{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham_24.txt ham 0.4231\n",
      "ham_3.txt ham 0.0001\n",
      "ham_4.txt ham 0.033\n",
      "spam_11.txt spam 1.0\n",
      "spam_14.txt ham 0.4541\n",
      "***********************Wrong Prediction***********************\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'gbk' codec can't decode byte 0xb0 in position 66: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8654fb17c6c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-8654fb17c6c4>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mham_word_pro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_word_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mham_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munion_set\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 单词在ham中的出现频率字典\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mspam_word_pro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_word_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspam_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munion_set\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 单词在spam里的出现频率字典\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mrig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mham_word_pro\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspam_word_pro\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mright_rate_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrig\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 返回正确率\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mwrong_spam_rate_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrg\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 返回误报spam->ham占比\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-8654fb17c6c4>\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(ham_word_pro, spam_word_pro, test_file)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mprob_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 统计测试集所出现单词word的P(spam|word)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mPsw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-8654fb17c6c4>\u001b[0m in \u001b[0;36memail_parser\u001b[1;34m(email_path)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# 去特殊字符标点符号，返回纯单词列表clean_word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mpunctuations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\",.<>()*&^%$#@!'\";~`[]{}|、\\\\/~+_-=?\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mcontent_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gbk'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mclean_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-8654fb17c6c4>\u001b[0m in \u001b[0;36mreadtxt\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m# 按encoding方式按行读取path路径文件所有行，返回行列表lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'gbk' codec can't decode byte 0xb0 in position 66: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "# from fwalker import fun\n",
    "# from reader import readtxt\n",
    "import os\n",
    "import shutil                           # 移动文件\n",
    "import random                           # 随机化抽取文件\n",
    "import numpy as np                      # 画图\n",
    "import matplotlib.pyplot as plt         # 画图\n",
    "from nltk.corpus import stopwords       # 去停用词\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")    # 选用英文停用词词典\n",
    "\n",
    "def fileWalker(path):\n",
    "    # 遍历语料目录，将所有语料文件绝对路径存入列表fileArray\n",
    "    fileArray = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for fn in files:\n",
    "            eachpath = str(root+'\\\\'+fn)\n",
    "            fileArray.append(eachpath)\n",
    "    return fileArray\n",
    "\n",
    "\n",
    "def test_set_select():\n",
    "    # 从spam和ham集中随机选10封移动到test集中作为测试集\n",
    "    filepath = r'..\\email'\n",
    "    testpath = r'..\\email\\test'\n",
    "    files = fileWalker(filepath)\n",
    "    random.shuffle(files)\n",
    "    top10 = files[:10]\n",
    "    for ech in top10:\n",
    "        ech_name = testpath+'\\\\'+('_'.join(ech.split('\\\\')[-2:]))  # 取分割后的后两项用_拼接\n",
    "        shutil.move(ech, testpath)  # 把ech移动到testpath文件夹下\n",
    "        os.rename(testpath+'\\\\'+ech.split('\\\\')[-1], ech_name)  # 把ech更名为ech_name,其实可以和上一步合并\n",
    "        # print('%s moved' % ech_name)\n",
    "    return\n",
    "\n",
    "\n",
    "def test_set_clear():\n",
    "    # 移动test测试集中文件回spam和ham中，等待重新抽取测试集\n",
    "    filepath = r'..\\email'\n",
    "    testpath = r'..\\email\\test'\n",
    "    files = fileWalker(testpath)\n",
    "    for ech in files:\n",
    "        ech_initial = filepath + '\\\\' + '\\\\'.join(' '.join(ech.split('\\\\')[-1:]).split('_'))  # 分析出文件移入测试集前的目录及名称\n",
    "        ech_move = filepath + '\\\\' + (' '.join(ech.split('\\\\')[-1:]).split('_'))[0]  # 分析出文件移入测试集前的目录\n",
    "        shutil.move(ech, ech_move)  # 把ech移动到ech_move文件夹下\n",
    "        os.rename(ech_move+'\\\\'+' '.join(ech.split('\\\\')[-1:]), ech_initial)  # 恢复原名称\n",
    "        # print('%s moved' % ech)\n",
    "    return\n",
    "\n",
    "\n",
    "def readtxt(path, encoding):\n",
    "    # 按encoding方式按行读取path路径文件所有行，返回行列表lines\n",
    "    with open(path, 'r', encoding=encoding) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "def fileWalker(path):\n",
    "    # 获取path路径下所有文件的绝对路径列表fileArray\n",
    "    fileArray = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for fn in files:\n",
    "            eachpath = str(root+'\\\\'+fn)\n",
    "            fileArray.append(eachpath)\n",
    "    return fileArray\n",
    "\n",
    "def email_parser(email_path):\n",
    "    # 去特殊字符标点符号，返回纯单词列表clean_word\n",
    "    punctuations = \"\"\",.<>()*&^%$#@!'\";~`[]{}|、\\\\/~+_-=?\"\"\"\n",
    "    content_list = readtxt(email_path, 'gbk')\n",
    "    content = (' '.join(content_list)).replace('\\r\\n', ' ').replace('\\t', ' ')\n",
    "    clean_word = []\n",
    "    for punctuation in punctuations:\n",
    "        content = (' '.join(content.split(punctuation))).replace('  ', ' ')\n",
    "        clean_word = [word.lower()\n",
    "                      for word in content.split(' ') if word.lower() not in cachedStopWords and len(word) > 2]\n",
    "        # 此处去了停用词，可不去，影响不大\n",
    "    return clean_word\n",
    "\n",
    "\n",
    "def get_word(email_file):\n",
    "    # 获取email_file路径下所有文件的总单词列表，append入word_list，extend入word_set并去重转为set\n",
    "    word_list = []\n",
    "    word_set = []\n",
    "    email_paths = fileWalker(email_file)\n",
    "    for email_path in email_paths:\n",
    "        clean_word = email_parser(email_path)\n",
    "        word_list.append(clean_word)\n",
    "        word_set.extend(clean_word)\n",
    "        # print(set(word_set))\n",
    "    return word_list, set(word_set)\n",
    "\n",
    "\n",
    "def count_word_prob(email_list, union_set):\n",
    "    # 返回训练集词频字典word_prob\n",
    "    word_prob = {}\n",
    "    for word in union_set:\n",
    "        counter = 0\n",
    "        for email in email_list:\n",
    "            if word in email:\n",
    "                counter += 1\n",
    "            else:\n",
    "                continue\n",
    "        prob = 0.0\n",
    "        if counter != 0:\n",
    "            prob = counter/len(email_list)\n",
    "        else:\n",
    "            prob = 0.05  # 进在某一分类中未出现则令该分类下该词词频TF=0.01，0.05，……，越大越会把spam误判成ham\n",
    "        word_prob[word] = prob\n",
    "    return word_prob\n",
    "\n",
    "\n",
    "def filter(ham_word_pro, spam_word_pro, test_file):\n",
    "    # 进行一次对测试集(10封邮件)的测试，输出对测试集的判断结果\n",
    "    # 并返回准确率right_rate，以及把spam误判成ham和总误判次数对应情况\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    wrong_spam = 0\n",
    "    test_paths = fileWalker(test_file)\n",
    "    for test_path in test_paths:\n",
    "        # 贝叶斯推断计算与判别实现\n",
    "        email_spam_prob = 0.0\n",
    "        spam_prob = 0.5  # 假设P(spam) = 0.5\n",
    "        ham_prob = 0.5  # P(ham) = 0.5\n",
    "        file_name = test_path.split('\\\\')[-1]\n",
    "        prob_dict = {}\n",
    "        words = set(email_parser(test_path))\n",
    "        for word in words:  # 统计测试集所出现单词word的P(spam|word)\n",
    "            Psw = 0.0\n",
    "            if word not in spam_word_pro:\n",
    "                Psw = 0.4  # 第一次出现的新单词设P(spam|new word) = 0.4 by Paul Graham\n",
    "            else:\n",
    "                Pws = spam_word_pro[word]  # P(word|spam)\n",
    "                Pwh = ham_word_pro[word]  # P(word|ham)\n",
    "                Psw = spam_prob*(Pws/(Pwh*ham_prob+Pws*spam_prob))\n",
    "                # P(spam|word) = P(spam)*P(word|spam)/P(word)\n",
    "                #              = P(spam)*P(word|spam)/(P(word|ham)*P(ham)+P(word|spam)*P(spam))\n",
    "            prob_dict[word] = Psw\n",
    "        numerator = 1\n",
    "        denominator_h = 1\n",
    "        for k, v in prob_dict.items():\n",
    "            numerator *= v  # P1P2…Pn = P(spam|word1)*P(spam|word2)*…*P(spam|wordn)\n",
    "            denominator_h *= (1-v)  # (1-P1)(1-P2)…(1-Pn) = (1-P(spam|word1))*(1-P(spam|word2))*…*(1-P(spam|wordn))\n",
    "        email_spam_prob = round(numerator/(numerator+denominator_h), 4)\n",
    "        # P(spam|word1word2…wordn) = P1P2…Pn/(P1P2…Pn+(1-P1)(1-P2)…(1-Pn))\n",
    "\n",
    "        if email_spam_prob > 0.9:  # P(spam|word1word2…wordn) > 0.9 认为是spam垃圾邮件\n",
    "            print(file_name, 'spam', email_spam_prob)\n",
    "            if file_name.split('_')[1] == '25.txt':\n",
    "                print(prob_dict)\n",
    "            if file_name.split('_')[0] == 'spam':  # 记录是否判断准确\n",
    "                right += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "                print('***********************Wrong Prediction***********************')\n",
    "        else:\n",
    "            print(file_name, 'ham', email_spam_prob)\n",
    "            if file_name.split('_')[1] == '25.txt':\n",
    "                print(prob_dict)\n",
    "            if file_name.split('_')[0] == 'ham':  # 记录是否判断准确\n",
    "                right += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "                wrong_spam += 1  # 记录把spam误判成ham的次数\n",
    "                print('***********************Wrong Prediction***********************')\n",
    "\n",
    "        # print(prob_dict)\n",
    "    right_rate = right/(right+wrong)  # 计算一个测试集的准确率\n",
    "    if wrong != 0:\n",
    "        wrong_spam_rate = [wrong_spam, wrong]  # [把spam误判成ham的次数，总误判次数]\n",
    "    else:\n",
    "        wrong_spam_rate = [-1]  # 表示总误判次数为0\n",
    "    return right_rate, wrong_spam_rate\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 主函数\n",
    "    right_rate_list = []\n",
    "    wrong_spam_rate_list = []\n",
    "    ham_file = r'D:\\email\\ham'\n",
    "    spam_file = r'D:\\email\\spam'\n",
    "    test_file = r'D:\\email\\test'\n",
    "    for i in range(100):\n",
    "        # 进行100次抽取测试集，测试并记录准确率，注意训练集应不包含测试集\n",
    "        test_set_select()  # 构造测试集\n",
    "        ham_list, ham_set = get_word(ham_file)\n",
    "        spam_list, spam_set = get_word(spam_file)\n",
    "        union_set = ham_set | spam_set  # 合并纯单词集合\n",
    "        ham_word_pro = count_word_prob(ham_list, union_set)  # 单词在ham中的出现频率字典\n",
    "        spam_word_pro = count_word_prob(spam_list, union_set)  # 单词在spam里的出现频率字典\n",
    "        rig, wrg = filter(ham_word_pro, spam_word_pro, test_file)\n",
    "        right_rate_list.append(rig)  # 返回正确率\n",
    "        wrong_spam_rate_list.append(wrg)  # 返回误报spam->ham占比\n",
    "        test_set_clear()  # 还原测试集\n",
    "    # 画出100次判别的准确率散点图\n",
    "    x = range(100)\n",
    "    y = right_rate_list\n",
    "    plt.scatter(x, y)\n",
    "    plt.title('Correct Rate of 100 Times')\n",
    "    plt.show()\n",
    "    # 输出100次误报spam->ham占比列表\n",
    "    print(wrong_spam_rate_list)\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
